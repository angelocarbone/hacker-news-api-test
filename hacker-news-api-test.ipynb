{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing “Ask HN: Who is hiring?” with Python and Hacker News API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you heard of [Hacker News](https://news.ycombinator.com/)? It’s a great mini social network dedicated to all things tech. Once a month they post a thread called [“Ask HN: Who is hiring?”](https://news.ycombinator.com/item?id=15824597), where anyone can list their job openings.\n",
    "\n",
    "With hundreds of comments it quickly gets overwhelming. Turns out it’s very easy to get the same data via [Hacker News API](https://github.com/HackerNews/API).\n",
    "\n",
    "For example, hitting [https://hacker-news.firebaseio.com/v0/item/8863.json?print=pretty](https://hacker-news.firebaseio.com/v0/item/8863.json?print=pretty) will return the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"by\" : \"dhouston\",\n",
    "  \"descendants\" : 71,\n",
    "  \"id\" : 8863,\n",
    "  \"kids\" : [ 8952, 9224, 8917, 8884, 8887, 8943, 8869, 8958, 9005, 9671, 9067, 8940, 8908, 9055, 8865, 8881, 8872, 8873, 8955, 10403, 8903, 8928, 9125, 8998, 8901, 8902, 8907, 8894, 8878, 8980, 8870, 8934, 8876 ],\n",
    "  \"score\" : 111,\n",
    "  \"time\" : 1175714200,\n",
    "  \"title\" : \"My YC app: Dropbox - Throw away your USB drive\",\n",
    "  \"type\" : \"story\",\n",
    "  \"url\" : \"http://www.getdropbox.com/u/2/screencast.html\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `kids` are all of the comments on post specified via id `8863`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Get the story ID\n",
    "\n",
    "Story ID is in the URL of the page. For example, URL for `Ask HN: Who is hiring? (December 2017)` is : `https://news.ycombinator.com/item?id=15824597`, so ID is `15824597`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Get the Post Content\n",
    "\n",
    "Content of the mains post is retrieved by changing ID in the Hacker News API link, resulting in `https://hacker-news.firebaseio.com/v0/item/15824597.json`.\n",
    "\n",
    "I created a function to construct the URL and used it to get the data, with the help of [requests](http://docs.python-requests.org/en/master/) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def getItemUrl(id):\n",
    "    return 'https://hacker-news.firebaseio.com/v0/item/{}.json'.format(str(id))\n",
    " \n",
    "storyID = 15824597\n",
    "story = requests.get(getItemUrl(storyID)).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I have the story and a list of IDs of all of the “kids”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a similar process for all of the kids to get their content. The “who is hiring” post had over 600 comments, so I used [tqdm](https://pypi.python.org/pypi/tqdm) module to show me the progress while I waited. I also used [list comprehension](http://www.pythonforbeginners.com/basics/list-comprehensions-in-python) instead of a regular `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 838/838 [08:23<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "comments = [requests.get(getItemUrl(c)).json() for c in tqdm(story['kids'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that I backed up all of the comments as a JSON file, just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"who-is-hiring.json\", \"w\") as f:\n",
    "    json.dump(comments, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Profit\n",
    "\n",
    "I only wanted to see jobs close to my home, so I made a new list only containing comments that had “CA” in them. Turned out that some comments were deleted and had no `text`, so I added a check for that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = [c for c in comments if \"text\" in c and \"CA\" in c['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common way to write location in the comment is like `San Francisco | CA`, so I’ve split every comment text by `CA`. I took the resulting left side and split it by empty space to get all of the words. Finally I took 3 words to the left of CA and combined them back into one sentence, hoping that it would give me a good signal for the location.\n",
    "\n",
    "I converted the list of locations to a set, in order to remove all duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '(Laguna Beach, ',\n",
       " '(Los Angeles), ',\n",
       " '(San Francisco, ',\n",
       " 'Area (Sunnyvale, ',\n",
       " 'Audit Trail (',\n",
       " 'Foreign nationals ',\n",
       " 'Frontend Engineers|Oakland, ',\n",
       " 'Huntington Beach, ',\n",
       " 'Los Angeles, ',\n",
       " 'Los Gatos, ',\n",
       " 'Menlo Park, ',\n",
       " 'Mountain View, ',\n",
       " 'Onsite|San Francisco, ',\n",
       " 'Palo Alto, ',\n",
       " 'Redwood City, ',\n",
       " 'SALARY: 80-110k ',\n",
       " 'San Diego, ',\n",
       " 'San Francisco, ',\n",
       " 'San Mateo ',\n",
       " 'San Mateo, ',\n",
       " 'San-Francisco, ',\n",
       " 'Santa Barbara, ',\n",
       " 'Santa Clara, ',\n",
       " 'Santa Cruz, ',\n",
       " 'Santa Monica, ',\n",
       " 'Systems (MES), S',\n",
       " 'VISA SPONSORSHIP, RELO',\n",
       " 'and Sunnyvale, ',\n",
       " 'and adjusting (PD',\n",
       " 'at <a href=\"http:&#x2F;&#x2F;smrtr.io&#x2F;X-cE',\n",
       " 'conferences.<p>Apply: <a href=\"https:&#x2F;&#x2F;hire.withgoogle.com&#x2F;public&#x2F;jobs&#x2F;rolepointcom&#x2F;view&#x2F;P_AAAAAA',\n",
       " 'following MINIMUM QUALIFI',\n",
       " 'here: <a href=\"https:&#x2F;&#x2F;ldd.tbe.taleo.net&#x2F;ldd03&#x2F;ats&#x2F;careers&#x2F;requisition.jsp?org=',\n",
       " 'our SF, ',\n",
       " 'solved so far:\\n',\n",
       " 'various AWESOME ',\n",
       " 'you:<p>Santa Barbara, ',\n",
       " '| Berkeley, ',\n",
       " '| Burbank, ',\n",
       " '| Irvine, ',\n",
       " '| Oakland, ',\n",
       " '| Sacramento, ',\n",
       " '| Sunnyvale, ',\n",
       " '| Venice, '}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = []\n",
    "for c in ca:\n",
    "    beforeca = c['text'].split(\"CA\")[0]         # Get everything to the left of CA\n",
    "    loc = \" \".join(beforeca.split(\" \")[-3:])    # Get 3 words before CA\n",
    "    locations.append(loc)                       # Save it\n",
    "set(locations)                                  # Remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got about 20 locations back. It was easy to look at all and identify a few that made sense for me. I picked out San Mateo and Redwood City.\n",
    "\n",
    "Finally I wrote all matching comments into an HTML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tocheck = [\"Redwood City\", \"San Mateo\"]\n",
    "\n",
    "import codecs\n",
    "\n",
    "with codecs.open(\"res.html\", \"w\", encoding=\"utf-8\") as f:       # Need codecs to write utf-8 in Python 2\n",
    "    for c in comments:\n",
    "        for check in tocheck:\n",
    "            if 'text' in c and check in c['text']:              # If desired city\n",
    "                f.write(c['text'])                              # Save to file\n",
    "                f.write(\"<hr/>\")                                # Separated by horizontal ruler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I opened results in a web browser using generated html file (res.html)\n",
    "\n",
    "I thought this was pretty handy. Thanks Hacker News!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resourses\n",
    "\n",
    "https://news.ycombinator.com/\n",
    "\n",
    "https://www.alexkras.com/parse-ask-hn-who-is-hiring-python-and-hacker-news-api/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
